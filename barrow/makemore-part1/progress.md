# Makemore Part 1 Progress Tracker

## Video: The spelled-out intro to language modeling: building makemore
**Duration:** 1h57m

**Description:** We implement a bigram character-level language model, which we will further complexify in followup videos into a modern Transformer language model, like GPT. In this video, the focus is on (1) introducing torch.Tensor and its subtleties and use in efficiently evaluating neural networks and (2) the overall framework of language modeling that includes model training, sampling, and the evaluation of a loss (e.g. the negative log likelihood for classification).

## Progress Score: 0/10

### Learning Objectives:
- [ ] Understand bigram character-level language models
- [ ] Learn torch.Tensor basics and efficient evaluation
- [ ] Implement language model training framework
- [ ] Understand sampling and loss evaluation
- [ ] Work with negative log likelihood for classification

### Notes:
*Add your notes and insights here as you progress through the video*

### Completed Sections:
*Track which parts of the video you've completed*

### Questions/Challenges:
*Note any questions or challenging concepts* 